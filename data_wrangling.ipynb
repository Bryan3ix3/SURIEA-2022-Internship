{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49830de7",
   "metadata": {},
   "source": [
    "## Seperate excel sheet sentences into individual text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d7de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(r'sentences2.xlsx')\n",
    "## the following is not universal. It's specific to the formating of this spreadsheet in particualar\n",
    "num = 1\n",
    "#write trancript for C1\n",
    "for i in range(len(df)):\n",
    "    phrase = str(df.iloc[i,0])\n",
    "    phrase = phrase[phrase.index('*')+1:] \n",
    "    open('./phrases/phrasesC1/C1AP%s.txt' % num, 'w').write(phrase) ## rewrites files if the name of files is unchanged, otherwise (new names) creates new files\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7105e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write trancript for C2\n",
    "num = 1\n",
    "for i in range(len(df)):\n",
    "    phrase = str(df.iloc[i,0])\n",
    "    phrase = phrase[phrase.index('*')+1:] \n",
    "    open('./phrases/phrasesC2/C2AP%s.txt' % num, 'w').write(phrase) ## rewrites files if the name of files is unchanged, otherwise (new names) creates new files\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7824ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write trancript for C22\n",
    "num = 1\n",
    "for i in range(len(df)):\n",
    "    phrase = str(df.iloc[i,0])\n",
    "    phrase = phrase[phrase.index('*')+1:] \n",
    "    open('./phrases/phrasesC22/C22MP%s.txt' % num, 'w').write(phrase) ## rewrites files if the name of files is unchanged, otherwise (new names) creates new files\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6b6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write trancript for M\n",
    "num = 1\n",
    "for i in range(len(df)):\n",
    "    phrase = str(df.iloc[i,0])\n",
    "    phrase = phrase[phrase.index('*')+1:] \n",
    "    open('./phrases/phrasesM/MP%s.txt' % num, 'w').write(phrase) ## rewrites files if the name of files is unchanged, otherwise (new names) creates new files\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885e8d7",
   "metadata": {},
   "source": [
    "## Merge dataframes and create sex column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ed70ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325, 22) (325, 22) (350, 22) (294, 22)\n"
     ]
    }
   ],
   "source": [
    "##load formant analysis for C1A\n",
    "# BAS web services succesfully analyzed only 80/95 recordings. 1,3,16,22,23,30,35,37,39,45,59,63,81,84,96\n",
    "C1AfaNO = pd.read_csv('C:/Users/bahan/OneDrive/Desktop/SURIEA Su22/results formants C1A/C1AformantAnalysis_emuDB/FormantAnalysis/csv_output/FormantSummaryNoOutliersMean.csv')\n",
    "C1AfaNO['English_Variety'] = 0\n",
    "\n",
    "##load formant analysis for C2A\n",
    "# BAS web services succesfully analyzed only 80/95 recordings. 1,3,16,22,23,30,35,37,39,45,59,63,81,84,96\n",
    "C2AfaNO = pd.read_csv('C:/Users/bahan/OneDrive/Desktop/SURIEA Su22/results formants C2A/C2AformantAnalysis_emuDB/FormantAnalysis/csv_output/FormantSummaryNoOutliersMean.csv')\n",
    "C2AfaNO['English_Variety'] = 0\n",
    "\n",
    "##load formant analysis for C22A\n",
    "# BAS web services succesfully analyzed only 85/100 recordings. 1,3,16,22,23,30,35,37,39,45,59,63,81,84,96\n",
    "C22MfaNO = pd.read_csv('C:/Users/bahan/OneDrive/Desktop/SURIEA Su22/results formants C22M/C22MformantAnalysis_emuDB/FormantAnalysis/csv_output/FormantSummaryNoOutliersMean.csv')\n",
    "C22MfaNO['English_Variety'] = 1\n",
    "\n",
    "##load formant analysis for M\n",
    "# BAS web services succesfully analyzed only 85/100 recordings. 1,3,16,22,23,30,35,37,39,45,59,63,81,84,96\n",
    "MfaNO = pd.read_csv('C:/Users/bahan/OneDrive/Desktop/SURIEA Su22/results formants M/MformantAnalysis_emuDB/FormantAnalysis/csv_output/FormantSummaryNoOutliersMean.csv')\n",
    "MfaNO['English_Variety'] = 1\n",
    "\n",
    "print(C1AfaNO.shape, C2AfaNO.shape, C22MfaNO.shape, MfaNO.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6346c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1289    1\n",
       "1290    1\n",
       "1291    1\n",
       "1292    1\n",
       "1293    1\n",
       "Name: English_Variety, Length: 1294, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mal_faNO = C1AfaNO.append([C2AfaNO,C22MfaNO, MfaNO], ignore_index=True)\n",
    "print(mal_faNO.shape)\n",
    "mal_faNO['sex'] = 0\n",
    "mal_faNO.English_Variety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36e66c0",
   "metadata": {},
   "source": [
    "## Separate sentences for femmes into individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca99086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = pd.read_excel(r'sentences3Fem.xlsx')\n",
    "## the ollowing is not universal. It's specific to the formating of this spreadsheet in particualar\n",
    "num = 1\n",
    "#write trancript for C19AH\n",
    "for i in range(len(df2)):\n",
    "    phrase = str(df2.iloc[i,0])\n",
    "    phrase = phrase[phrase.index('. ')+2:] \n",
    "    open('./phrases/phrasesC19/C19AH%s.txt' % num, 'w').write(phrase) ## rewrites files if the name of files is unchanged, otherwise (new names) creates new files\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af7a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "#write trancript for C20AH\n",
    "for i in range(len(df2)):\n",
    "    phrase = str(df2.iloc[i,0])\n",
    "    phrase = phrase[phrase.index('. ')+2:] \n",
    "    open('./phrases/phrasesC20/C20AH%s.txt' % num, 'w').write(phrase) ## rewrites files if the name of files is unchanged, otherwise (new names) creates new files\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1a99753",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "#write trancript for C10MH\n",
    "for i in range(len(df2)):\n",
    "    phrase = str(df2.iloc[i,0])\n",
    "    phrase = phrase[phrase.index('. ')+2:] \n",
    "    open('./phrases/phrasesC10/C10MH%s.txt' % num, 'w').write(phrase) ## rewrites files if the name of files is unchanged, otherwise (new names) creates new files\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721f80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "#write trancript for C14AH\n",
    "for i in range(len(df2)):\n",
    "    phrase = str(df2.iloc[i,0])\n",
    "    phrase = phrase[phrase.index('. ')+2:] \n",
    "    open('./phrases/phrasesC14/C14AH%s.txt' % num, 'w').write(phrase) ## rewrites files if the name of files is unchanged, otherwise (new names) creates new files\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac3c374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "#write trancript for C17MH\n",
    "for i in range(len(df2)):\n",
    "    phrase = str(df2.iloc[i,0])\n",
    "    phrase = phrase[phrase.index('. ')+2:] \n",
    "    open('./phrases/phrasesC17/C17MH%s.txt' % num, 'w').write(phrase) ## rewrites files if the name of files is unchanged, otherwise (new names) creates new files\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f42fa1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "#write trancript for C18MH\n",
    "for i in range(len(df2)):\n",
    "    phrase = str(df2.iloc[i,0])\n",
    "    phrase = phrase[phrase.index('. ')+2:] \n",
    "    open('./phrases/phrasesC18/C18MH%s.txt' % num, 'w').write(phrase) ## rewrites files if the name of files is unchanged, otherwise (new names) creates new files\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d088a5de",
   "metadata": {},
   "source": [
    "## Merge dataframes and add sex column (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b346154",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load formant analysis for C1A\n",
    "# BAS web services succesfully analyzed only 170/170 recordings\n",
    "C20AHfaNO = pd.read_csv('C:/Users/bahan/OneDrive/Desktop/SURIEA Su22/results formants C20AH/C20AHformantAnalysis_emuDB/FormantAnalysis/csv_output/FormantSummaryNoOutliersMean.csv')\n",
    "C20AHfaNO['English_Variety'] = 0\n",
    "\n",
    "# BAS web services succesfully analyzed only 170/170 recordings\n",
    "C19AHfaNO = pd.read_csv('C:/Users/bahan/OneDrive/Desktop/SURIEA Su22/results formants C19AH/C19AHformantAnalysis_emuDB/FormantAnalysis/csv_output/FormantSummaryNoOutliersMean.csv')\n",
    "C19AHfaNO['English_Variety'] = 0\n",
    "\n",
    "# BAS web services succesfully analyzed only 170/170 recordings\n",
    "C10MHfaNO = pd.read_csv('C:/Users/bahan/OneDrive/Desktop/SURIEA Su22/results formants C10MH/C10MHformantAnalysis_emuDB/FormantAnalysis/csv_output/FormantSummaryNoOutliersMean.csv')\n",
    "C10MHfaNO['English_Variety'] = 1\n",
    "\n",
    "# BAS web services succesfully analyzed only 170/170 recordings\n",
    "C14AHfaNO = pd.read_csv('C:/Users/bahan/OneDrive/Desktop/SURIEA Su22/results formants C14AH/C14AHformantAnalysis_emuDB/FormantAnalysis/csv_output/FormantSummaryNoOutliersMean.csv')\n",
    "C14AHfaNO['English_Variety'] = 0\n",
    "\n",
    "# BAS web services succesfully analyzed only 170/170 recordings\n",
    "C17MHfaNO = pd.read_csv('C:/Users/bahan/OneDrive/Desktop/SURIEA Su22/results formants C17MH/C17MHformantAnalysis_emuDB/FormantAnalysis/csv_output/FormantSummaryNoOutliersMean.csv')\n",
    "C17MHfaNO['English_Variety'] = 1\n",
    "\n",
    "# BAS web services succesfully analyzed only 164/164 recordings\n",
    "C18MHfaNO = pd.read_csv('C:/Users/bahan/OneDrive/Desktop/SURIEA Su22/results formants C18MH/C18MHformantAnalysis_emuDB/FormantAnalysis/csv_output/FormantSummaryNoOutliersMean.csv')\n",
    "C18MHfaNO['English_Variety'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94c990e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1425, 23)\n",
      "(1294, 23)\n",
      "(2719, 23)\n"
     ]
    }
   ],
   "source": [
    "fem_faNO = C14AHfaNO.append([C20AHfaNO,C19AHfaNO,C17MHfaNO,C18MHfaNO,C10MHfaNO], ignore_index=True)\n",
    "fem_faNO['sex'] = 1\n",
    "print(fem_faNO.shape)\n",
    "print(mal_faNO.shape)\n",
    "both_faNO = mal_faNO.append(fem_faNO, ignore_index=True)\n",
    "both_faNO[['sex', 'English_Variety']]\n",
    "print(both_faNO.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6dd9f",
   "metadata": {},
   "source": [
    "## Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0776c25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVGmedianF1</th>\n",
       "      <th>AVGmedianF2</th>\n",
       "      <th>AVGmedianF3</th>\n",
       "      <th>AVGmedianF4</th>\n",
       "      <th>AVGmeanF1</th>\n",
       "      <th>AVGmeanF2</th>\n",
       "      <th>AVGmeanF3</th>\n",
       "      <th>AVGmeanF4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fem_FaNO</th>\n",
       "      <td>599.033766</td>\n",
       "      <td>1786.402761</td>\n",
       "      <td>2616.677513</td>\n",
       "      <td>3858.811297</td>\n",
       "      <td>595.229319</td>\n",
       "      <td>1782.854864</td>\n",
       "      <td>2614.453854</td>\n",
       "      <td>3857.778213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mal_faNO</th>\n",
       "      <td>434.492925</td>\n",
       "      <td>1683.744781</td>\n",
       "      <td>2396.208827</td>\n",
       "      <td>3363.135011</td>\n",
       "      <td>432.986285</td>\n",
       "      <td>1682.007931</td>\n",
       "      <td>2395.661337</td>\n",
       "      <td>3363.951351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AVGmedianF1  AVGmedianF2  AVGmedianF3  AVGmedianF4   AVGmeanF1  \\\n",
       "fem_FaNO   599.033766  1786.402761  2616.677513  3858.811297  595.229319   \n",
       "mal_faNO   434.492925  1683.744781  2396.208827  3363.135011  432.986285   \n",
       "\n",
       "            AVGmeanF2    AVGmeanF3    AVGmeanF4  \n",
       "fem_FaNO  1782.854864  2614.453854  3857.778213  \n",
       "mal_faNO  1682.007931  2395.661337  3363.951351  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating dict of averages for each paramenter for male and female\n",
    "data= {'AVGmedianF1': [fem_faNO.medianF1Hz.mean(), mal_faNO.medianF1Hz.mean()],\n",
    "        'AVGmedianF2': [fem_faNO.medianF2Hz.mean(), mal_faNO.medianF2Hz.mean()],\n",
    "        'AVGmedianF3': [fem_faNO.medianF3Hz.mean(), mal_faNO.medianF3Hz.mean()],\n",
    "        'AVGmedianF4': [fem_faNO.medianF4Hz.mean(), mal_faNO.medianF4Hz.mean()],\n",
    "        'AVGmeanF1': [fem_faNO.meanF1Hz.mean(), mal_faNO.meanF1Hz.mean()],\n",
    "        'AVGmeanF2': [fem_faNO.meanF2Hz.mean(), mal_faNO.meanF2Hz.mean()],\n",
    "        'AVGmeanF3': [fem_faNO.meanF3Hz.mean(), mal_faNO.meanF3Hz.mean()],\n",
    "        'AVGmeanF4': [fem_faNO.meanF4Hz.mean(), mal_faNO.meanF4Hz.mean()]}\n",
    "\n",
    "desc = pd.DataFrame(data, index = ['fem_FaNO', 'mal_faNO'])\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76552d3d",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb38a51b",
   "metadata": {},
   "source": [
    "### Check for multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06cec299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19932.13815144932\n",
      "        Feature           VIF\n",
      "0  medianF1Bark   2177.626607\n",
      "1  medianF2Bark  19369.340295\n",
      "2  medianF3Bark  29050.067768\n",
      "3  medianF4Bark  26812.399776\n",
      "4    meanF1Bark   2199.741064\n",
      "5    meanF2Bark  19970.849049\n",
      "6    meanF3Bark  31011.438934\n",
      "7    meanF4Bark  28865.641718\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif_data = pd.DataFrame()\n",
    "thing = both_faNO.drop(['filename', 'Phoneme', 'StartMs', 'EndMs', 'midDistanceMean'], axis=1)\n",
    "thing = thing.loc[:,thing.columns.str.endswith('Bark')]\n",
    "#thing = thing.iloc[:, :8]#.append(both_faNO[['sex', 'English_Variety']], ignore_index = True)\n",
    "vif_data['Feature'] = thing.columns\n",
    "vif_data['VIF']= [variance_inflation_factor(thing.values, i) for i in range(len(thing.columns))]\n",
    "print((vif_data.VIF).mean())\n",
    "#print(both_faNO.columns)\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b3c75",
   "metadata": {},
   "source": [
    "### Splitting data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "006857d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##prepare data set for train/test split\n",
    "##dropping because Logistic regression requires ints, these variables aren't ints\n",
    "X = both_faNO.drop(['sex', 'filename', 'Phoneme','StartMs', 'EndMs', 'midDistanceMean'], axis=1) \n",
    "X = X.loc[:,~X.columns.str.endswith('Bark')]\n",
    "X = X.iloc[:, :8]\n",
    "y = both_faNO['sex']\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.20, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8b7bbb",
   "metadata": {},
   "source": [
    "### Running Logit M vs F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afe988a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.329041\n",
      "         Iterations 8\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                    sex   No. Observations:                 2175\n",
      "Model:                        MNLogit   Df Residuals:                     2166\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Thu, 28 Jul 2022   Pseudo R-squ.:                  0.5246\n",
      "Time:                        00:47:23   Log-Likelihood:                -715.66\n",
      "converged:                       True   LL-Null:                       -1505.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "     sex=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -32.5395      1.453    -22.389      0.000     -35.388     -29.691\n",
      "medianF1Hz     0.0074      0.005      1.487      0.137      -0.002       0.017\n",
      "medianF2Hz     0.0070      0.003      2.599      0.009       0.002       0.012\n",
      "medianF3Hz    -0.0011      0.002     -0.512      0.608      -0.005       0.003\n",
      "medianF4Hz    -0.0040      0.001     -3.868      0.000      -0.006      -0.002\n",
      "meanF1Hz       0.0031      0.005      0.617      0.537      -0.007       0.013\n",
      "meanF2Hz      -0.0014      0.003     -0.525      0.600      -0.007       0.004\n",
      "meanF3Hz       0.0018      0.002      0.808      0.419      -0.003       0.006\n",
      "meanF4Hz       0.0085      0.001      7.482      0.000       0.006       0.011\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "## Using sklearn\n",
    "model1 = LogisticRegression(random_state=0, multi_class='multinomial', penalty='none', max_iter=5000).fit(X_train, y_train)\n",
    "preds = model1.predict(X_test)\n",
    "\n",
    "## using stats models\n",
    "logit_model=sm.MNLogit(y_train,sm.add_constant(X_train))\n",
    "\n",
    "result=logit_model.fit()\n",
    "stats1=result.summary()\n",
    "print(stats1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cb436f",
   "metadata": {},
   "source": [
    "### Calculate Odds Ratios & 95% Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a738226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008536227572039534\n",
      "1.010514897040722 1.0065614324973693\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.exp(.0085)-1)\n",
    "print(math.exp(.0085+1.96*.001),math.exp(.0085-1.96*.001) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82a187",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e7417c",
   "metadata": {},
   "source": [
    "Logistic Regression was used to analyze the relationship between perceived gender and the means and medians of formants F1-F4.\n",
    "\n",
    "It was found that holding all other variables constant, the odds of being perceived as female grew by 0.85% percent (95% CI [.011, .007]) for each 1Hz increment of the mean F4 frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a5afb",
   "metadata": {},
   "source": [
    "### Accuracy M vs F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee34e086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_Female</th>\n",
       "      <th>predicted_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>224</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>28</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted_Female  predicted_Male\n",
       "Female               224              31\n",
       "Male                  28             261"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "#Create a confusion matrix\n",
    "#y_test as first argument and the preds as second argument \n",
    "confusion_matrix(y_test, preds)\n",
    "\n",
    "#transform confusion matrix into array\n",
    "#the matrix is stored in a vaiable called confmtrx\n",
    "confmtrx = np.array(confusion_matrix(y_test, preds))\n",
    "#Create DataFrame from confmtrx array \n",
    "#rows for test: Male, Female, as index \n",
    "#columns for preds: male, predicted_female, as column\n",
    "\n",
    "pd.DataFrame(confmtrx, index=['Female','Male'],\n",
    "columns=['predicted_Female','predicted_Male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca751b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8915441176470589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       255\n",
      "           1       0.89      0.90      0.90       289\n",
      "\n",
      "    accuracy                           0.89       544\n",
      "   macro avg       0.89      0.89      0.89       544\n",
      "weighted avg       0.89      0.89      0.89       544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics \n",
    "#Accuracy statistics\n",
    "\n",
    "print('Accuracy Score:', metrics.accuracy_score(y_test, preds))  \n",
    "\n",
    "#Create classification report\n",
    "class_report=classification_report(y_test, preds)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c10ea2",
   "metadata": {},
   "source": [
    "### Running Logit AA vs MUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfd35e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##prepare data set for train/test split\n",
    "##dropping because Logistic regression requires ints, these variables aren't ints\n",
    "X = both_faNO.drop(['filename', 'Phoneme', 'English_Variety'], axis=1) \n",
    "X = X.loc[:,~X.columns.str.endswith('Bark')]\n",
    "X = X.iloc[:, :8]\n",
    "y = both_faNO['English_Variety']\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.20, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88a2d1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653828\n",
      "         Iterations 5\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:        English_Variety   No. Observations:                 2175\n",
      "Model:                        MNLogit   Df Residuals:                     2166\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Thu, 28 Jul 2022   Pseudo R-squ.:                 0.05608\n",
      "Time:                        00:47:23   Log-Likelihood:                -1422.1\n",
      "converged:                       True   LL-Null:                       -1506.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.113e-32\n",
      "=====================================================================================\n",
      "English_Variety=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                -3.1426      0.569     -5.520      0.000      -4.258      -2.027\n",
      "medianF1Hz           -0.0028      0.003     -0.842      0.400      -0.009       0.004\n",
      "medianF2Hz           -0.0018      0.002     -0.883      0.377      -0.006       0.002\n",
      "medianF3Hz           -0.0026      0.001     -1.765      0.077      -0.005       0.000\n",
      "medianF4Hz            0.0005      0.001      0.621      0.535      -0.001       0.002\n",
      "meanF1Hz              0.0057      0.003      1.718      0.086      -0.001       0.012\n",
      "meanF2Hz              0.0016      0.002      0.806      0.420      -0.002       0.006\n",
      "meanF3Hz              0.0043      0.002      2.830      0.005       0.001       0.007\n",
      "meanF4Hz             -0.0011      0.001     -1.494      0.135      -0.003       0.000\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "## Using sklearn\n",
    "model2 = LogisticRegression(random_state=0, multi_class='multinomial', penalty='none', max_iter=5000).fit(X_train, y_train)\n",
    "preds2 = model2.predict(X_test)\n",
    "\n",
    "## using stats models\n",
    "logit_model2=sm.MNLogit(y_train,sm.add_constant(X_train))\n",
    "\n",
    "result2=logit_model2.fit()\n",
    "stats2=result2.summary()\n",
    "print(stats2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72db276d",
   "metadata": {},
   "source": [
    "### Calculate Odds Ratios & 95% Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c67cf7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0043092582654238\n",
      "1.00825387695925 1.0003800722091463\n"
     ]
    }
   ],
   "source": [
    "print(math.exp(.0043))\n",
    "print(math.exp(.0043+1.96*.002),math.exp(.0043-1.96*.002) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa952d77",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f0f69b",
   "metadata": {},
   "source": [
    "Logistic Regression was used to analyze the relationship between English variety and the means and medians of formants F1-F4.\n",
    "\n",
    "It was found that holding all other variables constant, the odds of a speaker using MUSE grew by .43% percent (95% CI [.0004, .008]) for each 1Hz increment of the mean F3 frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45eb088",
   "metadata": {},
   "source": [
    "### Accuracy AA vs MUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43c96206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_AA</th>\n",
       "      <th>predicted_MUSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>195</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUSE</th>\n",
       "      <td>122</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted_AA  predicted_MUSE\n",
       "AA             195              84\n",
       "MUSE           122             143"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a confusion matrix\n",
    "#y_test as first argument and the preds as second argument \n",
    "confusion_matrix(y_test, preds2)\n",
    "\n",
    "#transform confusion matrix into array\n",
    "#the matrix is stored in a vaiable called confmtrx\n",
    "confmtrx = np.array(confusion_matrix(y_test, preds2))\n",
    "#Create DataFrame from confmtrx array \n",
    "#rows for test: Male, Female, as index \n",
    "#columns for preds: male, predicted_female, as column\n",
    "\n",
    "pd.DataFrame(confmtrx, index=['AA','MUSE'],\n",
    "columns=['predicted_AA','predicted_MUSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96d375c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.6213235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.65       279\n",
      "           1       0.63      0.54      0.58       265\n",
      "\n",
      "    accuracy                           0.62       544\n",
      "   macro avg       0.62      0.62      0.62       544\n",
      "weighted avg       0.62      0.62      0.62       544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Accuracy statistics\n",
    "\n",
    "print('Accuracy Score:', metrics.accuracy_score(y_test, preds2))  \n",
    "\n",
    "#Create classification report\n",
    "class_report=classification_report(y_test, preds2)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70b0fc",
   "metadata": {},
   "source": [
    "### Intersectional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e69d15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##women control group\n",
    "##prepare data set for train/test split\n",
    "##dropping because Logistic regression requires ints, these variables aren't ints\n",
    "X = both_faNO[both_faNO.sex==1].drop(['filename', 'Phoneme', 'English_Variety'], axis=1) \n",
    "X = X.loc[:,~X.columns.str.endswith('Bark')]\n",
    "X = X.iloc[:, :8]\n",
    "y = both_faNO[both_faNO.sex==1]['English_Variety']\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.20, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "843d0775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.637947\n",
      "         Iterations 5\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:        English_Variety   No. Observations:                 1140\n",
      "Model:                        MNLogit   Df Residuals:                     1131\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Thu, 28 Jul 2022   Pseudo R-squ.:                 0.07584\n",
      "Time:                        00:47:23   Log-Likelihood:                -727.26\n",
      "converged:                       True   LL-Null:                       -786.94\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.487e-22\n",
      "=====================================================================================\n",
      "English_Variety=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                -3.1004      1.073     -2.889      0.004      -5.204      -0.997\n",
      "medianF1Hz           -0.0050      0.004     -1.283      0.199      -0.013       0.003\n",
      "medianF2Hz            0.0041      0.003      1.576      0.115      -0.001       0.009\n",
      "medianF3Hz           -0.0006      0.002     -0.362      0.717      -0.004       0.003\n",
      "medianF4Hz           -0.0018      0.001     -1.911      0.056      -0.004    4.71e-05\n",
      "meanF1Hz              0.0084      0.004      2.099      0.036       0.001       0.016\n",
      "meanF2Hz             -0.0048      0.003     -1.809      0.070      -0.010       0.000\n",
      "meanF3Hz             -0.0005      0.002     -0.288      0.773      -0.004       0.003\n",
      "meanF4Hz              0.0032      0.001      3.054      0.002       0.001       0.005\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "## Using sklearn\n",
    "model2 = LogisticRegression(random_state=0, multi_class='multinomial', penalty='none', max_iter=5000).fit(X_train, y_train)\n",
    "preds2 = model2.predict(X_test)\n",
    "\n",
    "## using stats models\n",
    "logit_model2=sm.MNLogit(y_train,sm.add_constant(X_train))\n",
    "\n",
    "result2=logit_model2.fit()\n",
    "stats2=result2.summary()\n",
    "print(stats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "253a16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##men control group\n",
    "##prepare data set for train/test split\n",
    "##dropping because Logistic regression requires ints, these variables aren't ints\n",
    "X = both_faNO[both_faNO.sex==0].drop(['filename', 'Phoneme', 'English_Variety'], axis=1) \n",
    "X = X.loc[:,~X.columns.str.endswith('Bark')]\n",
    "X = X.iloc[:, :8]\n",
    "y = both_faNO[both_faNO.sex==0]['English_Variety']\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.20, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bfd275f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.417325\n",
      "         Iterations 7\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:        English_Variety   No. Observations:                 1035\n",
      "Model:                        MNLogit   Df Residuals:                     1026\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Thu, 28 Jul 2022   Pseudo R-squ.:                  0.3979\n",
      "Time:                        00:47:24   Log-Likelihood:                -431.93\n",
      "converged:                       True   LL-Null:                       -717.40\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.148e-118\n",
      "=====================================================================================\n",
      "English_Variety=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const               -28.4238      2.130    -13.347      0.000     -32.598     -24.250\n",
      "medianF1Hz           -0.0118      0.010     -1.220      0.223      -0.031       0.007\n",
      "medianF2Hz           -0.0019      0.004     -0.423      0.672      -0.011       0.007\n",
      "medianF3Hz           -0.0031      0.005     -0.675      0.499      -0.012       0.006\n",
      "medianF4Hz            0.0018      0.002      0.824      0.410      -0.002       0.006\n",
      "meanF1Hz              0.0251      0.010      2.560      0.010       0.006       0.044\n",
      "meanF2Hz              0.0045      0.004      1.008      0.313      -0.004       0.013\n",
      "meanF3Hz              0.0126      0.005      2.667      0.008       0.003       0.022\n",
      "meanF4Hz             -0.0031      0.002     -1.371      0.171      -0.007       0.001\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "## Using sklearn\n",
    "model2 = LogisticRegression(random_state=0, multi_class='multinomial', penalty='none', max_iter=5000).fit(X_train, y_train)\n",
    "preds2 = model2.predict(X_test)\n",
    "\n",
    "## using stats models\n",
    "logit_model2=sm.MNLogit(y_train,sm.add_constant(X_train))\n",
    "\n",
    "result2=logit_model2.fit()\n",
    "stats2=result2.summary()\n",
    "print(stats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7b64eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0254176571632279\n",
      "1.0457140986172913 1.0055151527673363\n",
      "\n",
      "1.0126797144488495\n",
      "1.022652763774634 1.0028039236612292\n"
     ]
    }
   ],
   "source": [
    "print(math.exp(.0251))\n",
    "print(math.exp(.0251+1.96*.010),math.exp(.0251-1.96*.010))\n",
    "print()\n",
    "print(math.exp(.0126))\n",
    "print(math.exp(.0126+1.96*.005),math.exp(.0126-1.96*.005))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "998db513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7567567567567568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76       130\n",
      "           1       0.76      0.75      0.75       129\n",
      "\n",
      "    accuracy                           0.76       259\n",
      "   macro avg       0.76      0.76      0.76       259\n",
      "weighted avg       0.76      0.76      0.76       259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a confusion matrix\n",
    "#y_test as first argument and the preds as second argument \n",
    "confusion_matrix(y_test, preds2)\n",
    "\n",
    "#transform confusion matrix into array\n",
    "#the matrix is stored in a vaiable called confmtrx\n",
    "confmtrx = np.array(confusion_matrix(y_test, preds2))\n",
    "#Create DataFrame from confmtrx array \n",
    "#rows for test: Male, Female, as index \n",
    "#columns for preds: male, predicted_female, as column\n",
    "\n",
    "pd.DataFrame(confmtrx, index=['AA','MUSE'],\n",
    "columns=['predicted_AA','predicted_MUSE'])\n",
    "\n",
    "#Accuracy statistics\n",
    "\n",
    "print('Accuracy Score:', metrics.accuracy_score(y_test, preds2))  \n",
    "\n",
    "#Create classification report\n",
    "class_report=classification_report(y_test, preds2)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bdce846",
   "metadata": {},
   "outputs": [],
   "source": [
    "##MUSE control group\n",
    "##prepare data set for train/test split\n",
    "##dropping because Logistic regression requires ints, these variables aren't ints\n",
    "X = both_faNO[both_faNO.English_Variety==1].drop(['filename', 'Phoneme', 'sex'], axis=1) \n",
    "X = X.loc[:,~X.columns.str.endswith('Bark')]\n",
    "X = X.iloc[:, :8]\n",
    "y = both_faNO[both_faNO.English_Variety==1]['sex']\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.20, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe989b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.332846\n",
      "         Iterations 7\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                    sex   No. Observations:                 1055\n",
      "Model:                        MNLogit   Df Residuals:                     1046\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Thu, 28 Jul 2022   Pseudo R-squ.:                  0.5195\n",
      "Time:                        00:47:24   Log-Likelihood:                -351.15\n",
      "converged:                       True   LL-Null:                       -730.81\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.197e-158\n",
      "==============================================================================\n",
      "     sex=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -29.3860      2.087    -14.083      0.000     -33.476     -25.296\n",
      "medianF1Hz     0.0041      0.008      0.542      0.588      -0.011       0.019\n",
      "medianF2Hz     0.0075      0.004      2.011      0.044       0.000       0.015\n",
      "medianF3Hz    -0.0022      0.003     -0.851      0.394      -0.007       0.003\n",
      "medianF4Hz    -0.0049      0.001     -4.007      0.000      -0.007      -0.003\n",
      "meanF1Hz       0.0053      0.008      0.698      0.485      -0.010       0.020\n",
      "meanF2Hz      -0.0020      0.004     -0.517      0.605      -0.009       0.005\n",
      "meanF3Hz       0.0003      0.003      0.105      0.916      -0.005       0.006\n",
      "meanF4Hz       0.0103      0.001      7.332      0.000       0.008       0.013\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "## Using sklearn\n",
    "model2 = LogisticRegression(random_state=0, multi_class='multinomial', penalty='none', max_iter=5000).fit(X_train, y_train)\n",
    "preds2 = model2.predict(X_test)\n",
    "\n",
    "## using stats models\n",
    "logit_model2=sm.MNLogit(y_train,sm.add_constant(X_train))\n",
    "\n",
    "result2=logit_model2.fit()\n",
    "stats2=result2.summary()\n",
    "print(stats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "213eb453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0103532275910965\n",
      "1.0123354618721911 1.0083748746842032\n"
     ]
    }
   ],
   "source": [
    "print(math.exp(.0103))\n",
    "print(math.exp(.0103+1.96*.001),math.exp(.0103-1.96*.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18fc85f",
   "metadata": {},
   "source": [
    "Logistic Regression was used to analyze the relationship between MUSE speaker and the means and medians of formants F1-F4.\n",
    "\n",
    "It was found that holding all other variables constant, the odds of being a MUSE speaker grew by 1% percent (95% CI [.008, .012]) for each 1Hz increment of the mean F4 frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cb8f855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7575757575757576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74       132\n",
      "           1       0.73      0.82      0.77       132\n",
      "\n",
      "    accuracy                           0.76       264\n",
      "   macro avg       0.76      0.76      0.76       264\n",
      "weighted avg       0.76      0.76      0.76       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a confusion matrix\n",
    "#y_test as first argument and the preds as second argument \n",
    "confusion_matrix(y_test, preds2)\n",
    "\n",
    "#transform confusion matrix into array\n",
    "#the matrix is stored in a vaiable called confmtrx\n",
    "confmtrx = np.array(confusion_matrix(y_test, preds2))\n",
    "#Create DataFrame from confmtrx array \n",
    "#rows for test: Male, Female, as index \n",
    "#columns for preds: male, predicted_female, as column\n",
    "\n",
    "pd.DataFrame(confmtrx, index=['AA','MUSE'],\n",
    "columns=['predicted_AA','predicted_MUSE'])\n",
    "\n",
    "#Accuracy statistics\n",
    "\n",
    "print('Accuracy Score:', metrics.accuracy_score(y_test, preds2))  \n",
    "\n",
    "#Create classification report\n",
    "class_report=classification_report(y_test, preds2)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9dbbfba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##AA control group\n",
    "##prepare data set for train/test split\n",
    "##dropping because Logistic regression requires ints, these variables aren't ints\n",
    "X = both_faNO[both_faNO.English_Variety==0].drop(['filename', 'Phoneme', 'sex'], axis=1) \n",
    "X = X.loc[:,~X.columns.str.endswith('Bark')]\n",
    "X = X.iloc[:, :8]\n",
    "y = both_faNO[both_faNO.English_Variety==0]['sex']\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.20, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9e25eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.196582\n",
      "         Iterations 9\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                    sex   No. Observations:                 1120\n",
      "Model:                        MNLogit   Df Residuals:                     1111\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Thu, 28 Jul 2022   Pseudo R-squ.:                  0.7157\n",
      "Time:                        00:56:26   Log-Likelihood:                -220.17\n",
      "converged:                       True   LL-Null:                       -774.38\n",
      "Covariance Type:            nonrobust   LLR p-value:                5.834e-234\n",
      "==============================================================================\n",
      "     sex=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -50.0141      3.499    -14.293      0.000     -56.873     -43.156\n",
      "medianF1Hz    -0.0164      0.009     -1.761      0.078      -0.035       0.002\n",
      "medianF2Hz     0.0145      0.006      2.337      0.019       0.002       0.027\n",
      "medianF3Hz    -0.0033      0.005     -0.650      0.516      -0.013       0.007\n",
      "medianF4Hz    -0.0032      0.003     -1.259      0.208      -0.008       0.002\n",
      "meanF1Hz       0.0356      0.010      3.663      0.000       0.017       0.055\n",
      "meanF2Hz      -0.0077      0.006     -1.230      0.219      -0.020       0.005\n",
      "meanF3Hz       0.0094      0.005      1.776      0.076      -0.001       0.020\n",
      "meanF4Hz       0.0074      0.003      2.738      0.006       0.002       0.013\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "## Using sklearn\n",
    "model2 = LogisticRegression(random_state=0, multi_class='multinomial', penalty='none', max_iter=5000).fit(X_train, y_train)\n",
    "preds2 = model2.predict(X_test)\n",
    "\n",
    "## using stats models\n",
    "logit_model2=sm.MNLogit(y_train,sm.add_constant(X_train))\n",
    "\n",
    "result2=logit_model2.fit()\n",
    "stats2=result2.summary()\n",
    "print(stats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math.exp(.0356))\n",
    "print(math.exp(.0356+1.96*.010),math.exp(.0356-1.96*.010))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddaeb02",
   "metadata": {},
   "source": [
    "Logistic Regression was used to analyze the relationship between AAE and the means and medians of formants F1-F4.\n",
    "\n",
    "It was found that holding all other variables constant, the odds of being perceived as female grew by 3.6% percent (95% CI [.016, .057]) for each 1Hz increment of the mean F4 frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3cf4151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92       123\n",
      "           1       0.94      0.92      0.93       157\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.92      0.93      0.92       280\n",
      "weighted avg       0.93      0.93      0.93       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a confusion matrix\n",
    "#y_test as first argument and the preds as second argument \n",
    "confusion_matrix(y_test, preds2)\n",
    "\n",
    "#transform confusion matrix into array\n",
    "#the matrix is stored in a vaiable called confmtrx\n",
    "confmtrx = np.array(confusion_matrix(y_test, preds2))\n",
    "#Create DataFrame from confmtrx array \n",
    "#rows for test: Male, Female, as index \n",
    "#columns for preds: male, predicted_female, as column\n",
    "\n",
    "pd.DataFrame(confmtrx, index=['AA','MUSE'],\n",
    "columns=['predicted_AA','predicted_MUSE'])\n",
    "\n",
    "#Accuracy statistics\n",
    "\n",
    "print('Accuracy Score:', metrics.accuracy_score(y_test, preds2))  \n",
    "\n",
    "#Create classification report\n",
    "class_report=classification_report(y_test, preds2)\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
